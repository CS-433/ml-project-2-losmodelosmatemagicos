{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformt Data with the constrain of 1 seconds , breaks and encoding for NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info before preprocesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from Preprocesing import Preprocesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I manually move the data (locally) inside this folder \n",
    "with open('./ml4science_data_fake.pkl', 'rb') as fp:\n",
    "    dl = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['sequences', 'index', 'available_demographics'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['learner_id', 'sequence', 'begin', 'end', 'gender', 'year', 'language', 'label'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dl.keys())\n",
    "dl['sequences'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin 0 - end 7.889: [0, 0, 0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3440621047581669]\n",
      "begin 7.889 - end 83.03: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.9999999999999999, 0.0]\n",
      "begin 83.03 - end 86.28: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14174189890531658]\n",
      "begin 86.28 - end 86.33: [0.0, 0.0, 0.0, 1.0, 0.006079027355622759, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "begin 87.278 - end 90.562: [0.0, 0.0, 0.0, 1.0, 0.3992705167173245, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "begin 90.562 - end 99.597: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3940424789567799]\n",
      "begin 99.597 - end 100.32: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.1239499399965717, 0.0, 0.0, 0.0]\n",
      "begin 101.267 - end 107.071: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0772414527355239, 0.0]\n",
      "begin 108.989 - end 114.653: [0.0, 0.0, 0.0, 1.0, 0.6886322188449855, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "begin 115.424 - end 115.935: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.08760500600034259, 0.0, 0.0, 0.0]\n",
      "begin 117.488 - end 135.421: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.2386579896461318, 0.0]\n",
      "begin 136.702 - end 144.927: [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "begin 144.927 - end 147.995: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13380435256661938]\n",
      "begin 147.995 - end 149.956: [0.0, 0.0, 0.0, 1.0, 0.23841945288753624, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "begin 150.243 - end 150.934: [0.0, 0.0, 0.0, 1.0, 0.08401215805471161, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(15):\n",
    "    print('begin {} - end {}: {}'.format(dl['sequences'][0]['begin'][i], dl['sequences'][0]['end'][i], dl['sequences'][0]['sequence'][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repair FAKE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"for i in range(len(dl['sequences'])):\n",
    "    for j in range(len(dl['sequences'][i]['sequence'])): \n",
    "        non_zero_count = np.count_nonzero(dl['sequences'][i]['sequence'][j])\n",
    "        if non_zero_count != 2:\n",
    "            #add randomly a one in of of the four first values of the sequence\n",
    "            dl['sequences'][i]['sequence'][j][np.random.randint(0,4)] = 1\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "[1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3564261315115266]\n",
      "[0.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.08771929824561517, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08745293331713845]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"for i in range(len(dl['sequences'])):\n",
    "    for j in range(len(dl['sequences'][i]['sequence'])): \n",
    "        non_zero_count = np.count_nonzero(dl['sequences'][i]['sequence'][j])\n",
    "        if non_zero_count != 2:\n",
    "            print(f\"Vector at student {i}, sequence {j} has {non_zero_count} non-zero values\")\n",
    "            non_zero_positions = np.nonzero(dl['sequences'][i]['sequence'][j])[0]\n",
    "            print(f\"Positions of non-zero values: {non_zero_positions}\")\n",
    "\n",
    "# Manual check\n",
    "print(dl['sequences'][20]['sequence'][1])\n",
    "print(dl['sequences'][20]['sequence'][2])\n",
    "print(dl['sequences'][28]['sequence'][1])\n",
    "print(dl['sequences'][28]['sequence'][2])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data in a pkl file\n",
    "#with open('./ml4science_data_fake_repaired.pkl', 'wb') as fp:\n",
    "#    pickle.dump(dl, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for create Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dict={'[PAD]': 1, '[SEP]': 2, '[MASK]': 3} # PAD -> 0 is mush better\n",
    "tf = Preprocesing(num_states=4, num_actions=6, token_dict=token_dict, sep=15)\n",
    "\n",
    "encoded = tf.encode_vocabulary(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin 0 - end 7.889: 27\n",
      "begin 7.889 - end 83.03: 2\n",
      "begin 83.03 - end 86.28: 27\n",
      "begin 86.28 - end 86.33: 22\n",
      "begin 87.278 - end 90.562: 22\n",
      "begin 90.562 - end 99.597: 27\n",
      "begin 99.597 - end 100.32: 24\n",
      "begin 101.267 - end 107.071: 26\n",
      "begin 108.989 - end 114.653: 22\n",
      "begin 115.424 - end 115.935: 24\n",
      "begin 117.488 - end 135.421: 2\n",
      "begin 136.702 - end 144.927: 22\n",
      "begin 144.927 - end 147.995: 27\n",
      "begin 147.995 - end 149.956: 22\n",
      "begin 150.243 - end 150.934: 22\n"
     ]
    }
   ],
   "source": [
    "for i in range(15): #range(len(dl['sequences'][0]['begin'])):\n",
    "    print(\n",
    "        'begin {} - end {}: {}'.format\n",
    "        (encoded['sequences'][0]['begin'][i],\n",
    "        encoded['sequences'][0]['end'][i],\n",
    "        encoded['sequences'][0]['sequence'][i])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin 0 - end 7.889: [0, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
      "begin 7.889 - end 83.03: [0, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
      "begin 83.03 - end 86.28: [0, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
      "begin 86.28 - end 86.33: [0, 0, 0, 1, 1, 0, 0, 0, 0, 0]\n",
      "begin 87.278 - end 90.562: [0, 0, 0, 1, 1, 0, 0, 0, 0, 0]\n",
      "begin 90.562 - end 99.597: [0, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
      "begin 99.597 - end 100.32: [0, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
      "begin 101.267 - end 107.071: [0, 0, 0, 1, 0, 0, 0, 0, 1, 0]\n",
      "begin 108.989 - end 114.653: [0, 0, 0, 1, 1, 0, 0, 0, 0, 0]\n",
      "begin 115.424 - end 115.935: [0, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
      "begin 117.488 - end 135.421: [0, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
      "begin 136.702 - end 144.927: [0, 0, 0, 1, 1, 0, 0, 0, 0, 0]\n",
      "begin 144.927 - end 147.995: [0, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
      "begin 147.995 - end 149.956: [0, 0, 0, 1, 1, 0, 0, 0, 0, 0]\n",
      "begin 150.243 - end 150.934: [0, 0, 0, 1, 1, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "decoded = tf.decode_vocabulary(encoded)\n",
    "\n",
    "for i in range(15): #range(len(dl['sequences'][0]['begin'])):\n",
    "    print(\n",
    "        'begin {} - end {}: {}'.format\n",
    "        (decoded['sequences'][0]['begin'][i],\n",
    "        decoded['sequences'][0]['end'][i],\n",
    "        decoded['sequences'][0]['sequence'][i])\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

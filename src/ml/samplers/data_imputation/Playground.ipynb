{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformt Data with the constrain of 1 seconds , breaks and encoding for NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info before preprocesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from Vectorisation import Vectorisation\n",
    "from Config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I manually move the data (locally) inside this folder \n",
    "with open('./ml4science_data.pkl', 'rb') as fp:\n",
    "    dl = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['sequences', 'index', 'available_demographics'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['path', 'length', 'learner_id', 'raw_sequence', 'raw_begin', 'raw_end', 'last_timestamp', 'permutation', 'gender', 'year', 'language', 'begin', 'end', 'break_sequence', 'sequence', 'label', '1hot-sequence', 'nobreak', 'nobreak-1hot-sequence', 'stratifier_column'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dl.keys())\n",
    "dl['sequences'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin 0 - end 7.889: [0, 0, 0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3440621047581669]\n",
      "begin 7.889 - end 83.03: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.9999999999999999, 0.0]\n",
      "begin 83.03 - end 86.28: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14174189890531658]\n",
      "begin 86.28 - end 86.33: [0.0, 0.0, 0.0, 1.0, 0.006079027355622759, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "begin 87.278 - end 90.562: [0.0, 0.0, 0.0, 1.0, 0.3992705167173245, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "begin 90.562 - end 99.597: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3940424789567799]\n",
      "begin 99.597 - end 100.32: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.1239499399965717, 0.0, 0.0, 0.0]\n",
      "begin 101.267 - end 107.071: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0772414527355239, 0.0]\n",
      "begin 108.989 - end 114.653: [0.0, 0.0, 0.0, 1.0, 0.6886322188449855, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "begin 115.424 - end 115.935: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.08760500600034259, 0.0, 0.0, 0.0]\n",
      "begin 117.488 - end 135.421: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.2386579896461318, 0.0]\n",
      "begin 136.702 - end 144.927: [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "begin 144.927 - end 147.995: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13380435256661938]\n",
      "begin 147.995 - end 149.956: [0.0, 0.0, 0.0, 1.0, 0.23841945288753624, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "begin 150.243 - end 150.934: [0.0, 0.0, 0.0, 1.0, 0.08401215805471161, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(15):\n",
    "    print('begin {} - end {}: {}'.format(dl['sequences'][0]['begin'][i], dl['sequences'][0]['end'][i], dl['sequences'][0]['sequence'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.31496062992126 +- 102.75095652848267\n",
      "13\n",
      "819\n"
     ]
    }
   ],
   "source": [
    "student_seq = [len(dl['sequences'][i]['sequence']) for i in range(len(dl['sequences']))]\n",
    "\n",
    "print(np.mean(student_seq), '+-', np.std(student_seq))\n",
    "print(np.min(student_seq))\n",
    "print(np.max(student_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repair FAKE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for i in range(len(dl['sequences'])):\\n    for j in range(len(dl['sequences'][i]['sequence'])): \\n        non_zero_count = np.count_nonzero(dl['sequences'][i]['sequence'][j])\\n        if non_zero_count != 2:\\n            #add randomly a one in of of the four first values of the sequence\\n            dl['sequences'][i]['sequence'][j][np.random.randint(0,4)] = 1\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for i in range(len(dl['sequences'])):\n",
    "    for j in range(len(dl['sequences'][i]['sequence'])): \n",
    "        non_zero_count = np.count_nonzero(dl['sequences'][i]['sequence'][j])\n",
    "        if non_zero_count != 2:\n",
    "            #add randomly a one in of of the four first values of the sequence\n",
    "            dl['sequences'][i]['sequence'][j][np.random.randint(0,4)] = 1'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3564261315115266]\n",
      "[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34055533828705625]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dl['sequences'])):\n",
    "    for j in range(len(dl['sequences'][i]['sequence'])): \n",
    "        non_zero_count = np.count_nonzero(dl['sequences'][i]['sequence'][j])\n",
    "        if non_zero_count != 2:\n",
    "            print(f\"Vector at student {i}, sequence {j} has {non_zero_count} non-zero values\")\n",
    "            non_zero_positions = np.nonzero(dl['sequences'][i]['sequence'][j])[0]\n",
    "            print(f\"Positions of non-zero values: {non_zero_positions}\")\n",
    "\n",
    "# Manual check\n",
    "print(dl['sequences'][20]['sequence'][1])\n",
    "print(dl['sequences'][20]['sequence'][2])\n",
    "print(dl['sequences'][120]['sequence'][5])\n",
    "print(dl['sequences'][120]['sequence'][6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data in a pkl file\n",
    "#with open('./ml4science_data_fake_repaired.pkl', 'wb') as fp:\n",
    "#    pickle.dump(dl, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for create Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\yanni\\Documents\\Documents\\Programmes\\ml_project2\\src\\ml\\samplers\\data_imputation\\Playground.ipynb Cell 13\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yanni/Documents/Documents/Programmes/ml_project2/src/ml/samplers/data_imputation/Playground.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m token_dict\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39m[PAD]\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m[SEP]\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m[MASK]\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m3\u001b[39m} \u001b[39m# PAD -> 0 is mush better\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yanni/Documents/Documents/Programmes/ml_project2/src/ml/samplers/data_imputation/Playground.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m tf \u001b[39m=\u001b[39m Vectorisation(config\u001b[39m=\u001b[39mconfig, special_token_dict\u001b[39m=\u001b[39mtoken_dict, sep\u001b[39m=\u001b[39m\u001b[39m15\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/yanni/Documents/Documents/Programmes/ml_project2/src/ml/samplers/data_imputation/Playground.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m encoded \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mencode_vocabulary(dl)\n",
      "File \u001b[1;32mc:\\Users\\yanni\\Documents\\Documents\\Programmes\\ml_project2\\src\\ml\\samplers\\data_imputation\\Vectorisation.py:66\u001b[0m, in \u001b[0;36mVectorisation.encode_vocabulary\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     63\u001b[0m encoded_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(shape\u001b[39m=\u001b[39m(\u001b[39mlen\u001b[39m(data[\u001b[39m'\u001b[39m\u001b[39msequences\u001b[39m\u001b[39m'\u001b[39m]), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mMAX_LEN))\n\u001b[0;32m     65\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msep \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencode_sep(encoded_data)\n\u001b[0;32m     68\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(data[\u001b[39m'\u001b[39m\u001b[39msequences\u001b[39m\u001b[39m'\u001b[39m])):\n\u001b[0;32m     69\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(data[\u001b[39m'\u001b[39m\u001b[39msequences\u001b[39m\u001b[39m'\u001b[39m][i][\u001b[39m'\u001b[39m\u001b[39msequence\u001b[39m\u001b[39m'\u001b[39m])):\n",
      "File \u001b[1;32mc:\\Users\\yanni\\Documents\\Documents\\Programmes\\ml_project2\\src\\ml\\samplers\\data_imputation\\Vectorisation.py:90\u001b[0m, in \u001b[0;36mVectorisation.encode_sep\u001b[1;34m(self, data, break_idx)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencode_sep\u001b[39m(\u001b[39mself\u001b[39m, data: \u001b[39mdict\u001b[39m, break_idx: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m8\u001b[39m):\n\u001b[0;32m     79\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[39m    Encodes the breaks if longer than this value \"sep\", in the given data.\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39m        Index break value, by default 8.\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 90\u001b[0m     students \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39msequences\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     91\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(students)):\n\u001b[0;32m     92\u001b[0m             sequences \u001b[39m=\u001b[39m students[i][\u001b[39m'\u001b[39m\u001b[39msequence\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "\n",
    "token_dict={'[PAD]': 1, '[SEP]': 2, '[MASK]': 3} # PAD -> 0 is mush better\n",
    "tf = Vectorisation(config=config, special_token_dict=token_dict, sep=15)\n",
    "\n",
    "encoded = tf.encode_vocabulary(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin 0 - end 7.889: 27\n",
      "begin 7.889 - end 83.03: 2\n",
      "begin 83.03 - end 86.28: 27\n",
      "begin 86.28 - end 86.33: 22\n",
      "begin 87.278 - end 90.562: 22\n",
      "begin 90.562 - end 99.597: 27\n",
      "begin 99.597 - end 100.32: 24\n",
      "begin 101.267 - end 107.071: 26\n",
      "begin 108.989 - end 114.653: 22\n",
      "begin 115.424 - end 115.935: 24\n",
      "begin 117.488 - end 135.421: 2\n",
      "begin 136.702 - end 144.927: 22\n",
      "begin 144.927 - end 147.995: 27\n",
      "begin 147.995 - end 149.956: 22\n",
      "begin 150.243 - end 150.934: 22\n"
     ]
    }
   ],
   "source": [
    "for i in range(15): #range(len(dl['sequences'][0]['begin'])):\n",
    "    print(\n",
    "        'begin {} - end {}: {}'.format\n",
    "        (encoded['sequences'][0]['begin'][i],\n",
    "        encoded['sequences'][0]['end'][i],\n",
    "        encoded['sequences'][0]['sequence'][i])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin 0 - end 7.889: [0, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
      "begin 7.889 - end 83.03: [0, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
      "begin 83.03 - end 86.28: [0, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
      "begin 86.28 - end 86.33: [0, 0, 0, 1, 1, 0, 0, 0, 0, 0]\n",
      "begin 87.278 - end 90.562: [0, 0, 0, 1, 1, 0, 0, 0, 0, 0]\n",
      "begin 90.562 - end 99.597: [0, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
      "begin 99.597 - end 100.32: [0, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
      "begin 101.267 - end 107.071: [0, 0, 0, 1, 0, 0, 0, 0, 1, 0]\n",
      "begin 108.989 - end 114.653: [0, 0, 0, 1, 1, 0, 0, 0, 0, 0]\n",
      "begin 115.424 - end 115.935: [0, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
      "begin 117.488 - end 135.421: [0, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
      "begin 136.702 - end 144.927: [0, 0, 0, 1, 1, 0, 0, 0, 0, 0]\n",
      "begin 144.927 - end 147.995: [0, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
      "begin 147.995 - end 149.956: [0, 0, 0, 1, 1, 0, 0, 0, 0, 0]\n",
      "begin 150.243 - end 150.934: [0, 0, 0, 1, 1, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "decoded = tf.decode_vocabulary(encoded)\n",
    "\n",
    "for i in range(15): #range(len(dl['sequences'][0]['begin'])):\n",
    "    print(\n",
    "        'begin {} - end {}: {}'.format\n",
    "        (decoded['sequences'][0]['begin'][i],\n",
    "        decoded['sequences'][0]['end'][i],\n",
    "        decoded['sequences'][0]['sequence'][i])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

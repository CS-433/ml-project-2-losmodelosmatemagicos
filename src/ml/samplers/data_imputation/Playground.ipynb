{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformt Data with the constrain of 1 seconds , breaks and encoding for NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info before preprocesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from Preprocesing import Preprocesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I manually move the data (locally) inside this folder \n",
    "with open('./ml4science_data.pkl', 'rb') as fp:\n",
    "    dl = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['sequences', 'index', 'available_demographics'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['path', 'length', 'learner_id', 'raw_sequence', 'raw_begin', 'raw_end', 'last_timestamp', 'permutation', 'gender', 'year', 'language', 'begin', 'end', 'break_sequence', 'sequence', 'label', '1hot-sequence', 'nobreak', 'stratifier_column'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dl.keys())\n",
    "dl['sequences'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin 0 - end 7.889: [0, 0, 0, 1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3440621047581669]\n",
      "begin 7.889 - end 83.03: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.9999999999999999, 0.0]\n",
      "begin 83.03 - end 86.28: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14174189890531658]\n",
      "begin 86.28 - end 86.33: [0.0, 0.0, 0.0, 1.0, 0.006079027355622759, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "begin 87.278 - end 90.562: [0.0, 0.0, 0.0, 1.0, 0.3992705167173245, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "begin 90.562 - end 99.597: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3940424789567799]\n",
      "begin 99.597 - end 100.32: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.1239499399965717, 0.0, 0.0, 0.0]\n",
      "begin 101.267 - end 107.071: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0772414527355239, 0.0]\n",
      "begin 108.989 - end 114.653: [0.0, 0.0, 0.0, 1.0, 0.6886322188449855, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "begin 115.424 - end 115.935: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.08760500600034259, 0.0, 0.0, 0.0]\n",
      "begin 117.488 - end 135.421: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.2386579896461318, 0.0]\n",
      "begin 136.702 - end 144.927: [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "begin 144.927 - end 147.995: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13380435256661938]\n",
      "begin 147.995 - end 149.956: [0.0, 0.0, 0.0, 1.0, 0.23841945288753624, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "begin 150.243 - end 150.934: [0.0, 0.0, 0.0, 1.0, 0.08401215805471161, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(15):\n",
    "    print('begin {} - end {}: {}'.format(dl['sequences'][0]['begin'][i], dl['sequences'][0]['end'][i], dl['sequences'][0]['sequence'][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repair FAKE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for i in range(len(dl['sequences'])):\\n    for j in range(len(dl['sequences'][i]['sequence'])): \\n        non_zero_count = np.count_nonzero(dl['sequences'][i]['sequence'][j])\\n        if non_zero_count != 2:\\n            #add randomly a one in of of the four first values of the sequence\\n            dl['sequences'][i]['sequence'][j][np.random.randint(0,4)] = 1\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(dl['sequences'])):\n",
    "    for j in range(len(dl['sequences'][i]['sequence'])): \n",
    "        non_zero_count = np.count_nonzero(dl['sequences'][i]['sequence'][j])\n",
    "        if non_zero_count != 2:\n",
    "            #add randomly a one in of of the four first values of the sequence\n",
    "            dl['sequences'][i]['sequence'][j][np.random.randint(0,4)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for i in range(len(dl[\\'sequences\\'])):\\n    for j in range(len(dl[\\'sequences\\'][i][\\'sequence\\'])): \\n        non_zero_count = np.count_nonzero(dl[\\'sequences\\'][i][\\'sequence\\'][j])\\n        if non_zero_count != 2:\\n            print(f\"Vector at student {i}, sequence {j} has {non_zero_count} non-zero values\")\\n            non_zero_positions = np.nonzero(dl[\\'sequences\\'][i][\\'sequence\\'][j])[0]\\n            print(f\"Positions of non-zero values: {non_zero_positions}\")\\n\\n# Manual check\\nprint(dl[\\'sequences\\'][20][\\'sequence\\'][1])\\nprint(dl[\\'sequences\\'][20][\\'sequence\\'][2])\\nprint(dl[\\'sequences\\'][28][\\'sequence\\'][1])\\nprint(dl[\\'sequences\\'][28][\\'sequence\\'][2])'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(dl['sequences'])):\n",
    "    for j in range(len(dl['sequences'][i]['sequence'])): \n",
    "        non_zero_count = np.count_nonzero(dl['sequences'][i]['sequence'][j])\n",
    "        if non_zero_count != 2:\n",
    "            print(f\"Vector at student {i}, sequence {j} has {non_zero_count} non-zero values\")\n",
    "            non_zero_positions = np.nonzero(dl['sequences'][i]['sequence'][j])[0]\n",
    "            print(f\"Positions of non-zero values: {non_zero_positions}\")\n",
    "\n",
    "# Manual check\n",
    "print(dl['sequences'][20]['sequence'][1])\n",
    "print(dl['sequences'][20]['sequence'][2])\n",
    "print(dl['sequences'][28]['sequence'][1])\n",
    "print(dl['sequences'][28]['sequence'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data in a pkl file\n",
    "#with open('./ml4science_data_fake_repaired.pkl', 'wb') as fp:\n",
    "#    pickle.dump(dl, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for create Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\yanni\\Documents\\Documents\\Programmes\\ml_project2\\src\\ml\\samplers\\data_imputation\\Playground.ipynb Cell 12\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yanni/Documents/Documents/Programmes/ml_project2/src/ml/samplers/data_imputation/Playground.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m token_dict\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39m[PAD]\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m[SEP]\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m[MASK]\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m3\u001b[39m} \u001b[39m# PAD -> 0 is mush better\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yanni/Documents/Documents/Programmes/ml_project2/src/ml/samplers/data_imputation/Playground.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m tf \u001b[39m=\u001b[39m Preprocesing(num_states\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, num_actions\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m, token_dict\u001b[39m=\u001b[39mtoken_dict, sep\u001b[39m=\u001b[39m\u001b[39m15\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/yanni/Documents/Documents/Programmes/ml_project2/src/ml/samplers/data_imputation/Playground.ipynb#X32sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m encoded \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mencode_vocabulary(dl)\n",
      "File \u001b[1;32mc:\\Users\\yanni\\Documents\\Documents\\Programmes\\ml_project2\\src\\ml\\samplers\\data_imputation\\Preprocesing.py:61\u001b[0m, in \u001b[0;36mPreprocesing.encode_vocabulary\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     58\u001b[0m encoded_data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m     60\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msep \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 61\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencode_sep(encoded_data)\n\u001b[0;32m     63\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(data[\u001b[39m'\u001b[39m\u001b[39msequences\u001b[39m\u001b[39m'\u001b[39m])):\n\u001b[0;32m     64\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(data[\u001b[39m'\u001b[39m\u001b[39msequences\u001b[39m\u001b[39m'\u001b[39m][i][\u001b[39m'\u001b[39m\u001b[39msequence\u001b[39m\u001b[39m'\u001b[39m])):\n",
      "File \u001b[1;32mc:\\Users\\yanni\\Documents\\Documents\\Programmes\\ml_project2\\src\\ml\\samplers\\data_imputation\\Preprocesing.py:89\u001b[0m, in \u001b[0;36mPreprocesing.encode_sep\u001b[1;34m(self, data, break_idx)\u001b[0m\n\u001b[0;32m     87\u001b[0m sequences \u001b[39m=\u001b[39m students[i][\u001b[39m'\u001b[39m\u001b[39msequence\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     88\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(sequences)):\n\u001b[1;32m---> 89\u001b[0m     is_break_idx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnonzero(sequences[j])[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m break_idx\n\u001b[0;32m     90\u001b[0m     is_long_break \u001b[39m=\u001b[39m students[i][\u001b[39m'\u001b[39m\u001b[39mend\u001b[39m\u001b[39m'\u001b[39m][j] \u001b[39m-\u001b[39m students[i][\u001b[39m'\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m'\u001b[39m][j] \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msep\n\u001b[0;32m     91\u001b[0m     \u001b[39mif\u001b[39;00m (is_break_idx \u001b[39mand\u001b[39;00m is_long_break): \n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "token_dict={'[PAD]': 1, '[SEP]': 2, '[MASK]': 3} # PAD -> 0 is mush better\n",
    "tf = Preprocesing(num_states=4, num_actions=6, token_dict=token_dict, sep=15)\n",
    "\n",
    "encoded = tf.encode_vocabulary(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin 0 - end 7.889: 27\n",
      "begin 7.889 - end 83.03: 2\n",
      "begin 83.03 - end 86.28: 27\n",
      "begin 86.28 - end 86.33: 22\n",
      "begin 87.278 - end 90.562: 22\n",
      "begin 90.562 - end 99.597: 27\n",
      "begin 99.597 - end 100.32: 24\n",
      "begin 101.267 - end 107.071: 26\n",
      "begin 108.989 - end 114.653: 22\n",
      "begin 115.424 - end 115.935: 24\n",
      "begin 117.488 - end 135.421: 2\n",
      "begin 136.702 - end 144.927: 22\n",
      "begin 144.927 - end 147.995: 27\n",
      "begin 147.995 - end 149.956: 22\n",
      "begin 150.243 - end 150.934: 22\n"
     ]
    }
   ],
   "source": [
    "for i in range(15): #range(len(dl['sequences'][0]['begin'])):\n",
    "    print(\n",
    "        'begin {} - end {}: {}'.format\n",
    "        (encoded['sequences'][0]['begin'][i],\n",
    "        encoded['sequences'][0]['end'][i],\n",
    "        encoded['sequences'][0]['sequence'][i])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin 0 - end 7.889: [0, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
      "begin 7.889 - end 83.03: [0, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
      "begin 83.03 - end 86.28: [0, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
      "begin 86.28 - end 86.33: [0, 0, 0, 1, 1, 0, 0, 0, 0, 0]\n",
      "begin 87.278 - end 90.562: [0, 0, 0, 1, 1, 0, 0, 0, 0, 0]\n",
      "begin 90.562 - end 99.597: [0, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
      "begin 99.597 - end 100.32: [0, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
      "begin 101.267 - end 107.071: [0, 0, 0, 1, 0, 0, 0, 0, 1, 0]\n",
      "begin 108.989 - end 114.653: [0, 0, 0, 1, 1, 0, 0, 0, 0, 0]\n",
      "begin 115.424 - end 115.935: [0, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
      "begin 117.488 - end 135.421: [0, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
      "begin 136.702 - end 144.927: [0, 0, 0, 1, 1, 0, 0, 0, 0, 0]\n",
      "begin 144.927 - end 147.995: [0, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
      "begin 147.995 - end 149.956: [0, 0, 0, 1, 1, 0, 0, 0, 0, 0]\n",
      "begin 150.243 - end 150.934: [0, 0, 0, 1, 1, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "decoded = tf.decode_vocabulary(encoded)\n",
    "\n",
    "for i in range(15): #range(len(dl['sequences'][0]['begin'])):\n",
    "    print(\n",
    "        'begin {} - end {}: {}'.format\n",
    "        (decoded['sequences'][0]['begin'][i],\n",
    "        decoded['sequences'][0]['end'][i],\n",
    "        decoded['sequences'][0]['sequence'][i])\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

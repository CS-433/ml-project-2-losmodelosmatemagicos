{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT's playground \n",
    "Hello there! Welcome on BERT's playground. You may play with BERT here and see what he can do but always make sure he feels respected and admired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\yanni\\.conda\\envs\\ML\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import masking\n",
    "import BERT\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "from Vectorisation import Vectorisation\n",
    "from Config import Config\n",
    "from MaskedTextGenerator import MaskedTextGenerator\n",
    "\n",
    "with open(\"./ml4science_data.pkl\", \"rb\") as fp:\n",
    "    data_dict = pickle.load(fp)\n",
    "\n",
    "config = Config()\n",
    "vec = Vectorisation(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(254, 128) (254, 128) (254, 128)\n",
      "<_BatchDataset element_spec=(TensorSpec(shape=(None, 128), dtype=tf.int32, name=None), TensorSpec(shape=(None, 128), dtype=tf.int32, name=None), TensorSpec(shape=(None, 128), dtype=tf.float64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for masked language model\n",
    "encoded = vec.encode_dict(data_dict)\n",
    "x_masked_encoded, y_masked_encoded, sample_weights = masking.mask_input_and_labels(encoded, config.TOKEN_DICT, seed=32)\n",
    "print(x_masked_encoded.shape, y_masked_encoded.shape, sample_weights.shape)\n",
    "\n",
    "mlm_ds = tf.data.Dataset.from_tensor_slices((x_masked_encoded, y_masked_encoded, sample_weights))\n",
    "mlm_ds = mlm_ds.shuffle(1000).batch(config.BATCH_SIZE)\n",
    "\n",
    "print(mlm_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26  2 26 21 21 26 23 25 21 23  2 21 26 21 21 26 21 25  3  8  3  3  3  3\n",
      "  3  3  3  3  7  8  4  2  8  3 16 20 21 26 21 23 21  3  8  7  8  3  5  8\n",
      "  4  8  2  8  3  8 10  9 10  9  9 15 20 11  9 14 13 11  9 14 13 14 10 11\n",
      "  9  9 13 14 13 14 11  9 10 14 13 10 11  9 14  9 14 15 20 15 15 17 20  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "sample_tokens = x_masked_encoded[0:1]\n",
    "print(y_masked_encoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26  2 26 21 21 26  9 25 21 23  2 21 26 21 21 26 21  1  3  8  3  1  3  3\n",
      "  3  3  3  3  7  8  1  2  8  3 16 20 21 26 21 23 21  3  8  7  8  3  5  8\n",
      "  4  1  2  8  3  1 10  9 10  9  9 15  1 11  9  1  1 11  9 14 13 14 10  1\n",
      "  9  9 13 14 13 14 11  9 10 14 13 10 11  1 14  9  1 15 20 15 15 17 20  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(x_masked_encoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\yanni\\.conda\\envs\\ML\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "Model: \"masked_bert_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 128)]                0         []                            \n",
      "                                                                                                  \n",
      " word_embedding (Embedding)  (None, 128, 64)              1728      ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOp  (None, 128, 64)              0         ['word_embedding[0][0]']      \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " encoder_0/multiheadattenti  (None, 128, 64)              16640     ['tf.__operators__.add[0][0]',\n",
      " on (MultiHeadAttention)                                             'tf.__operators__.add[0][0]',\n",
      "                                                                     'tf.__operators__.add[0][0]']\n",
      "                                                                                                  \n",
      " encoder_0/att_dropout (Dro  (None, 128, 64)              0         ['encoder_0/multiheadattention\n",
      " pout)                                                              [0][0]']                      \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TF  (None, 128, 64)              0         ['tf.__operators__.add[0][0]',\n",
      " OpLambda)                                                           'encoder_0/att_dropout[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " encoder_0/att_layernormali  (None, 128, 64)              128       ['tf.__operators__.add_1[0][0]\n",
      " zation (LayerNormalization                                         ']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " encoder_0/ffn (Sequential)  (None, 128, 64)              8320      ['encoder_0/att_layernormaliza\n",
      "                                                                    tion[0][0]']                  \n",
      "                                                                                                  \n",
      " encoder_0/ffn_dropout (Dro  (None, 128, 64)              0         ['encoder_0/ffn[0][0]']       \n",
      " pout)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TF  (None, 128, 64)              0         ['encoder_0/att_layernormaliza\n",
      " OpLambda)                                                          tion[0][0]',                  \n",
      "                                                                     'encoder_0/ffn_dropout[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " encoder_0/ffn_layernormali  (None, 128, 64)              128       ['tf.__operators__.add_2[0][0]\n",
      " zation (LayerNormalization                                         ']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " mlm_cls (Dense)             (None, 128, 27)              1755      ['encoder_0/ffn_layernormaliza\n",
      "                                                                    tion[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 28701 (112.11 KB)\n",
      "Trainable params: 28699 (112.11 KB)\n",
      "Non-trainable params: 2 (8.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator_callback = MaskedTextGenerator(sample_tokens, config.TOKEN_DICT['[MASK]'])\n",
    "\n",
    "bert_masked_model = BERT.create_masked_language_bert_model(config)\n",
    "bert_masked_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 151ms/steposs: 3.17\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[21 26 14]       [26 21 10]       [26 14 21]       [26 14 21]       [22 26 21]       \n",
      "probabilities: \t[0.19 0.14 0.13] [0.21 0.17 0.11] [0.17 0.14 0.12] [0.14 0.11 0.11] [0.22 0.15 0.12] \n",
      "\n",
      "16/16 [==============================] - 2s 26ms/step - loss: 3.1173\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 17ms/steploss: 2.74\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[21 26 22]       [21 26 10]       [21 26 22]       [21 26 22]       [21 22 26]       \n",
      "probabilities: \t[0.3  0.16 0.07] [0.27 0.2  0.08] [0.2  0.16 0.1 ] [0.17 0.13 0.09] [0.18 0.16 0.14] \n",
      "\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 2.7299\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 17ms/steploss: 2.64\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 21 14]       [26 21 10]       [26 21 22]       [26 14 21]       [26 22 21]       \n",
      "probabilities: \t[0.23 0.22 0.07] [0.27 0.19 0.08] [0.18 0.13 0.11] [0.13 0.12 0.11] [0.16 0.16 0.12] \n",
      "\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 2.6503\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 17ms/steploss: 2.58\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[21 26 23]       [26 21  9]       [26 21 14]       [14 22 21]       [22 26 21]       \n",
      "probabilities: \t[0.25 0.22 0.09] [0.25 0.2  0.09] [0.16 0.14 0.11] [0.12 0.1  0.1 ] [0.15 0.12 0.11] \n",
      "\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 2.5846\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 16ms/steploss: 2.54\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[21 26 23]       [26 21  9]       [22 21 26]       [22 14  9]       [22  9 26]       \n",
      "probabilities: \t[0.26 0.18 0.09] [0.21 0.2  0.12] [0.17 0.14 0.11] [0.16 0.11 0.1 ] [0.2  0.1  0.09] \n",
      "\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 2.5475\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 17ms/steploss: 2.52\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[21 26 23]       [26 21  9]       [22 14 26]       [14 22 10]       [22 26 15]       \n",
      "probabilities: \t[0.23 0.22 0.1 ] [0.25 0.17 0.11] [0.15 0.14 0.12] [0.16 0.14 0.09] [0.17 0.1  0.08] \n",
      "\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 2.5204\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 16ms/steploss: 2.47\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[21 26 23]       [26 21  9]       [21 26 22]       [22 14 21]       [22 21 26]       \n",
      "probabilities: \t[0.27 0.26 0.13] [0.29 0.21 0.12] [0.17 0.16 0.14] [0.14 0.12 0.12] [0.17 0.13 0.13] \n",
      "\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 2.4883\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 16ms/steploss: 2.44\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[21 26 23]       [26 21  9]       [22 21 14]       [22 14 10]       [22 21  9]       \n",
      "probabilities: \t[0.25 0.21 0.12] [0.22 0.19 0.14] [0.18 0.13 0.13] [0.15 0.14 0.1 ] [0.18 0.1  0.09] \n",
      "\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 2.4466\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 17ms/steploss: 2.40\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[21 26 23]       [21 26  9]       [22 21 14]       [14 22  9]       [22 21  9]       \n",
      "probabilities: \t[0.26 0.18 0.16] [0.2  0.19 0.16] [0.14 0.14 0.14] [0.15 0.11 0.11] [0.14 0.11 0.11] \n",
      "\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 2.4026\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 16ms/steploss: 2.31\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[21 26 23]       [21 26  9]       [14 22 21]       [14 22 10]       [22 15 14]       \n",
      "probabilities: \t[0.28 0.17 0.12] [0.22 0.18 0.15] [0.16 0.16 0.13] [0.21 0.09 0.09] [0.12 0.12 0.12] \n",
      "\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 2.3184\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 15ms/steploss: 2.24\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[21 26 23]       [ 9 26 21]       [14  9 10]       [14  9 20]       [15  9 20]       \n",
      "probabilities: \t[0.23 0.21 0.16] [0.23 0.19 0.17] [0.16 0.13 0.1 ] [0.22 0.12 0.1 ] [0.19 0.12 0.11] \n",
      "\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 2.2298\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 18ms/steploss: 2.13\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[21 26 23]       [ 9 21 26]       [14  9 10]       [14  9 10]       [15  9 20]       \n",
      "probabilities: \t[0.29 0.2  0.14] [0.22 0.21 0.19] [0.15 0.13 0.13] [0.2  0.16 0.1 ] [0.21 0.15 0.11] \n",
      "\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 2.1569\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 17ms/steploss: 2.09\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 21 23]       [26 21 14]       [14 10 21]       [14  9 20]       [14 15 20]       \n",
      "probabilities: \t[0.28 0.26 0.17] [0.29 0.23 0.11] [0.23 0.1  0.09] [0.28 0.09 0.09] [0.17 0.16 0.12] \n",
      "\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 2.0942\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 16ms/steploss: 2.03\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[21 26 23]       [ 9 21 26]       [14 10 15]       [14  9 20]       [15  9 20]       \n",
      "probabilities: \t[0.24 0.17 0.17] [0.27 0.17 0.16] [0.17 0.14 0.13] [0.18 0.14 0.11] [0.19 0.14 0.13] \n",
      "\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 2.0392\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 16ms/steploss: 1.96\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[23 21 26]       [ 9 26 21]       [10 14 11]       [14 10 20]       [15 14 20]       \n",
      "probabilities: \t[0.22 0.21 0.18] [0.23 0.16 0.15] [0.19 0.19 0.12] [0.21 0.12 0.11] [0.16 0.14 0.13] \n",
      "\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.9758\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 17ms/steploss: 1.92\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 21 23]       [26 21  9]       [14 10 11]       [14  9 10]       [14 15  9]       \n",
      "probabilities: \t[0.34 0.25 0.12] [0.25 0.22 0.17] [0.22 0.16 0.12] [0.24 0.12 0.12] [0.16 0.14 0.13] \n",
      "\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.9255\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 18ms/steploss: 1.85\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 21 23]       [ 9 26 21]       [14 15 10]       [14 20  9]       [15 20  9]       \n",
      "probabilities: \t[0.3 0.2 0.2] [0.21 0.2  0.16] [0.17 0.13 0.11] [0.18 0.14 0.1 ] [0.15 0.14 0.13] \n",
      "\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.8576\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 16ms/steploss: 1.80\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 21 23]       [ 9 14 21]       [14 15 20]       [14  9 20]       [15 14  9]       \n",
      "probabilities: \t[0.28 0.27 0.15] [0.21 0.18 0.18] [0.22 0.19 0.08] [0.24 0.13 0.1 ] [0.18 0.17 0.15] \n",
      "\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.8021\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 17ms/steploss: 1.74\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[21 26 23]       [21 26  9]       [15 14 20]       [14  9 20]       [ 9 15 14]       \n",
      "probabilities: \t[0.29 0.27 0.24] [0.22 0.19 0.18] [0.21 0.18 0.1 ] [0.21 0.12 0.1 ] [0.17 0.17 0.16] \n",
      "\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.7486\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 17ms/steploss: 1.69\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[21 26 23]       [21  9 26]       [15 20 16]       [20 16 14]       [15 20  9]       \n",
      "probabilities: \t[0.4  0.22 0.21] [0.3  0.15 0.13] [0.31 0.17 0.16] [0.16 0.13 0.12] [0.21 0.15 0.13] \n",
      "\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.7056\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 17ms/steploss: 1.67\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[21 23 26]       [21 26 23]       [15 16 20]       [20  8 14]       [15  8 20]       \n",
      "probabilities: \t[0.38 0.25 0.23] [0.32 0.16 0.12] [0.32 0.17 0.15] [0.14 0.12 0.12] [0.2  0.14 0.14] \n",
      "\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.6723\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 17ms/steploss: 1.60\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 21 23]       [21 26  9]       [15 16 20]       [14  8 20]       [15 14  9]       \n",
      "probabilities: \t[0.33 0.32 0.2 ] [0.24 0.17 0.16] [0.32 0.17 0.13] [0.2  0.14 0.1 ] [0.17 0.17 0.16] \n",
      "\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.6075\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 16ms/steploss: 1.57\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[21 23 26]       [21 14  9]       [15 16 20]       [14 20  8]       [14 15  9]       \n",
      "probabilities: \t[0.38 0.3  0.16] [0.18 0.17 0.16] [0.25 0.24 0.16] [0.18 0.14 0.12] [0.17 0.17 0.16] \n",
      "\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.5779\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 16ms/steploss: 1.56\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[21 26 23]       [21  9 26]       [16 15 20]       [14  8 20]       [14  8  9]       \n",
      "probabilities: \t[0.4  0.27 0.19] [0.3  0.13 0.13] [0.3  0.19 0.11] [0.19 0.15 0.1 ] [0.2  0.15 0.14] \n",
      "\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.5606\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 16ms/steploss: 1.53\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 21 23]       [21  9 26]       [16 15 20]       [ 8 14 20]       [ 8 15  9]       \n",
      "probabilities: \t[0.37 0.28 0.17] [0.23 0.17 0.12] [0.35 0.2  0.1 ] [0.2  0.12 0.11] [0.18 0.17 0.14] \n",
      "\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.5259\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 16ms/steploss: 1.49\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[23 21 26]       [14  9 15]       [16 15  8]       [ 8 14 20]       [ 8 14 15]       \n",
      "probabilities: \t[0.39 0.3  0.14] [0.22 0.14 0.11] [0.31 0.13 0.1 ] [0.2  0.13 0.11] [0.2  0.19 0.12] \n",
      "\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1.4946\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 19ms/steploss: 1.46\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 21 23]       [ 9 14 21]       [16 15  8]       [ 8 14 20]       [14  8  9]       \n",
      "probabilities: \t[0.3  0.26 0.24] [0.22 0.19 0.11] [0.29 0.16 0.14] [0.26 0.17 0.1 ] [0.22 0.2  0.13] \n",
      "\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.4634\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 18ms/steploss: 1.44\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[21 23 26]       [ 9 14 21]       [16 15  8]       [ 8 14 20]       [14  8  9]       \n",
      "probabilities: \t[0.29 0.28 0.18] [0.3  0.18 0.09] [0.34 0.12 0.12] [0.25 0.14 0.1 ] [0.2  0.18 0.17] \n",
      "\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4429\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 19ms/steploss: 1.42\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[21 23 26]       [21  9 14]       [16  8 15]       [ 8 14  3]       [ 8 14 15]       \n",
      "probabilities: \t[0.38 0.25 0.24] [0.22 0.19 0.14] [0.28 0.17 0.15] [0.35 0.11 0.09] [0.28 0.21 0.1 ] \n",
      "\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.4308\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 15ms/steploss: 1.42\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 23 21]       [ 9 21 14]       [16  8  4]       [8 3 4]       [ 8 14  9]       \n",
      "probabilities: \t[0.29 0.27 0.22] [0.21 0.17 0.11] [0.3  0.21 0.09] [0.4  0.12 0.1 ] [0.32 0.15 0.1 ] \n",
      "\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.4175\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 19ms/steploss: 1.36\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[21 23 26]       [ 9 14  8]       [16  8  4]       [8 3 4]       [ 8 14  9]       \n",
      "probabilities: \t[0.28 0.27 0.25] [0.2  0.17 0.14] [0.24 0.23 0.12] [0.42 0.11 0.11] [0.33 0.21 0.08] \n",
      "\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3823\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 18ms/steploss: 1.35\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[21 26 23]       [ 9 14  8]       [16  8  4]       [8 4 3]       [ 8 14 20]       \n",
      "probabilities: \t[0.34 0.18 0.16] [0.28 0.19 0.1 ] [0.25 0.23 0.11] [0.39 0.12 0.11] [0.29 0.17 0.11] \n",
      "\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3745\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 17ms/steploss: 1.37\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[23 21 26]       [ 9 14  8]       [ 8 16  4]       [8 3 4]       [ 8 14  9]       \n",
      "probabilities: \t[0.28 0.25 0.18] [0.26 0.15 0.15] [0.26 0.18 0.14] [0.41 0.13 0.12] [0.28 0.18 0.16] \n",
      "\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.3639\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 17ms/steploss: 1.33\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 21 23]       [14  8  9]       [ 8 16  5]       [8 3 4]       [ 8 14 20]       \n",
      "probabilities: \t[0.31 0.25 0.19] [0.19 0.19 0.17] [0.33 0.15 0.14] [0.46 0.12 0.11] [0.3  0.24 0.07] \n",
      "\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3430\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 18ms/steploss: 1.33\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[23 21 22]       [ 9 14  8]       [8 5 4]       [8 3 4]       [ 8 14  9]       \n",
      "probabilities: \t[0.24 0.24 0.15] [0.29 0.18 0.14] [0.32 0.18 0.15] [0.45 0.15 0.14] [0.34 0.19 0.1 ] \n",
      "\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3340\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 18ms/steploss: 1.31\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[23 21 22]       [ 9 14  8]       [8 5 4]       [8 4 3]       [ 8 14 20]       \n",
      "probabilities: \t[0.21 0.21 0.19] [0.27 0.21 0.12] [0.37 0.18 0.13] [0.45 0.12 0.12] [0.31 0.22 0.08] \n",
      "\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.3107\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 17ms/steploss: 1.31\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 23 21]       [ 8 14  9]       [8 4 5]       [8 4 3]       [ 8 14  3]       \n",
      "probabilities: \t[0.26 0.26 0.16] [0.26 0.15 0.11] [0.39 0.23 0.2 ] [0.45 0.22 0.13] [0.42 0.14 0.09] \n",
      "\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.3095\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 17ms/steploss: 1.26\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[21 23 26]       [ 8 14  5]       [8 5 4]       [8 4 3]       [ 8 14  3]       \n",
      "probabilities: \t[0.27 0.24 0.15] [0.32 0.12 0.11] [0.37 0.22 0.21] [0.48 0.2  0.11] [0.44 0.13 0.09] \n",
      "\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.2927\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 18ms/steploss: 1.27\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[22 21 23]       [ 9 14  8]       [8 5 4]       [8 3 4]       [ 8 14  3]       \n",
      "probabilities: \t[0.31 0.19 0.15] [0.33 0.14 0.13] [0.34 0.24 0.13] [0.48 0.16 0.11] [0.3  0.19 0.1 ] \n",
      "\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.2778\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 21ms/steploss: 1.25\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[23 26 22]       [ 8 14  9]       [8 4 5]       [8 4 3]       [14  8 20]       \n",
      "probabilities: \t[0.24 0.22 0.18] [0.22 0.18 0.16] [0.31 0.19 0.19] [0.5  0.18 0.1 ] [0.29 0.27 0.08] \n",
      "\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.2522\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 20ms/steploss: 1.24\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[22 26 23]       [ 8  9 15]       [8 5 4]       [8 4 3]       [ 8 14  9]       \n",
      "probabilities: \t[0.33 0.22 0.2 ] [0.25 0.2  0.16] [0.38 0.23 0.12] [0.61 0.11 0.1 ] [0.36 0.2  0.11] \n",
      "\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.2416\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 20ms/steploss: 1.22\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 23 22]       [8 9 5]       [8 5 4]       [8 4 3]       [ 8 14  3]       \n",
      "probabilities: \t[0.31 0.29 0.14] [0.35 0.13 0.1 ] [0.44 0.22 0.16] [0.61 0.13 0.11] [0.44 0.12 0.09] \n",
      "\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.2401\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 19ms/steploss: 1.21\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[23 26 21]       [8 5 3]       [8 5 4]       [8 3 4]       [ 8 14  3]       \n",
      "probabilities: \t[0.26 0.21 0.19] [0.39 0.11 0.09] [0.45 0.24 0.14] [0.59 0.13 0.11] [0.43 0.18 0.1 ] \n",
      "\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.2276\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 18ms/steploss: 1.21\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[23 21 26]       [8 5 3]       [8 5 4]       [8 4 3]       [ 8  3 14]       \n",
      "probabilities: \t[0.35 0.27 0.12] [0.5  0.15 0.08] [0.46 0.27 0.18] [0.61 0.15 0.11] [0.53 0.11 0.09] \n",
      "\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.2027\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 18ms/steploss: 1.18\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[23 22 26]       [8 9 5]       [8 5 4]       [8 4 3]       [ 8  3 14]       \n",
      "probabilities: \t[0.33 0.2  0.18] [0.31 0.15 0.13] [0.4  0.31 0.18] [0.55 0.19 0.11] [0.44 0.12 0.11] \n",
      "\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.1933\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 17ms/steploss: 1.18\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[23 21 26]       [8 5 3]       [8 5 4]       [8 4 3]       [ 8 14  3]       \n",
      "probabilities: \t[0.31 0.24 0.17] [0.43 0.15 0.09] [0.43 0.27 0.16] [0.6  0.17 0.09] [0.44 0.19 0.07] \n",
      "\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1.1825\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 29ms/steploss: 1.17\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[23 26 21]       [8 5 3]       [8 5 4]       [8 4 3]       [ 8 14  3]       \n",
      "probabilities: \t[0.36 0.2  0.19] [0.49 0.15 0.09] [0.47 0.29 0.14] [0.6  0.16 0.12] [0.52 0.12 0.12] \n",
      "\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1.1640\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 40ms/steploss: 1.16\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[21 26 22]       [ 8  9 14]       [ 8  5 15]       [8 4 3]       [14  8  9]       \n",
      "probabilities: \t[0.26 0.25 0.24] [0.23 0.14 0.14] [0.35 0.23 0.11] [0.57 0.14 0.12] [0.32 0.26 0.09] \n",
      "\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 1.1641\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 42ms/steploss: 1.15\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[23 22 21]       [8 5 3]       [5 8 4]       [8 4 3]       [ 8  3 14]       \n",
      "probabilities: \t[0.32 0.27 0.15] [0.46 0.24 0.11] [0.39 0.39 0.13] [0.61 0.16 0.11] [0.54 0.12 0.09] \n",
      "\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 1.1605\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 33ms/steploss: 1.13\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[22 23 26]       [8 5 3]       [8 5 4]       [8 4 3]       [ 8  3 14]       \n",
      "probabilities: \t[0.27 0.23 0.2 ] [0.5  0.18 0.12] [0.45 0.33 0.12] [0.65 0.14 0.11] [0.58 0.14 0.07] \n",
      "\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 1.1401\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 45ms/steploss: 1.12\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[22 23 26]       [8 5 3]       [8 5 4]       [8 4 3]       [ 8  4 14]       \n",
      "probabilities: \t[0.24 0.24 0.24] [0.5  0.18 0.09] [0.41 0.29 0.2 ] [0.55 0.28 0.07] [0.49 0.12 0.1 ] \n",
      "\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.1308\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 44ms/steploss: 1.11\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[23 26 21]       [8 5 3]       [8 5 4]       [8 4 3]       [ 8  3 14]       \n",
      "probabilities: \t[0.36 0.27 0.18] [0.42 0.18 0.13] [0.43 0.38 0.1 ] [0.74 0.08 0.08] [0.55 0.11 0.08] \n",
      "\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 1.1158\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 56ms/steploss: 1.12\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[22 23 26]       [8 5 3]       [8 5 4]       [8 4 3]       [ 8  3 14]       \n",
      "probabilities: \t[0.28 0.27 0.21] [0.47 0.22 0.13] [0.39 0.34 0.19] [0.66 0.16 0.09] [0.53 0.12 0.08] \n",
      "\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 1.1153\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 44ms/steploss: 1.09\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[22 23 26]       [8 5 3]       [8 5 4]       [8 3 4]       [ 8 14  3]       \n",
      "probabilities: \t[0.45 0.21 0.17] [0.47 0.2  0.11] [0.44 0.4  0.08] [0.72 0.1  0.08] [0.5  0.16 0.11] \n",
      "\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 1.0990\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 35ms/steploss: 1.08\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[22 26 23]       [8 5 3]       [5 8 4]       [8 4 3]       [ 8  3 14]       \n",
      "probabilities: \t[0.3  0.23 0.23] [0.46 0.25 0.13] [0.43 0.36 0.13] [0.69 0.12 0.09] [0.53 0.13 0.11] \n",
      "\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 1.0871\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 45ms/steploss: 1.07\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 22 23]       [8 5 3]       [5 8 4]       [8 4 3]       [ 8  3 14]       \n",
      "probabilities: \t[0.31 0.26 0.22] [0.45 0.28 0.14] [0.45 0.32 0.17] [0.61 0.21 0.09] [0.49 0.14 0.12] \n",
      "\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 1.0716\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 49ms/steploss: 1.06\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 23 22]       [8 5 3]       [8 5 4]       [8 4 3]       [8 3 9]       \n",
      "probabilities: \t[0.34 0.29 0.18] [0.45 0.2  0.14] [0.42 0.32 0.16] [0.73 0.1  0.1 ] [0.49 0.13 0.11] \n",
      "\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 1.0729\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 47ms/steploss: 1.09\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 22 23]       [8 5 3]       [5 8 4]       [8 4 3]       [ 8  3 14]       \n",
      "probabilities: \t[0.37 0.22 0.19] [0.41 0.22 0.17] [0.41 0.33 0.19] [0.68 0.16 0.08] [0.48 0.13 0.11] \n",
      "\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 1.0830\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 53ms/steploss: 1.04\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 22 23]       [8 5 3]       [8 5 4]       [8 3 4]       [ 8  3 14]       \n",
      "probabilities: \t[0.37 0.2  0.19] [0.5  0.18 0.14] [0.42 0.31 0.17] [0.8  0.08 0.07] [0.54 0.12 0.11] \n",
      "\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 1.0511\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 38ms/steploss: 1.03\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 22 23]       [8 5 3]       [5 8 4]       [8 4 3]       [8 3 4]       \n",
      "probabilities: \t[0.3  0.27 0.22] [0.44 0.31 0.15] [0.44 0.36 0.15] [0.74 0.1  0.07] [0.6  0.15 0.07] \n",
      "\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 1.0407\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 46ms/steploss: 1.02\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 23 21]       [8 5 3]       [8 5 4]       [8 4 3]       [8 3 4]       \n",
      "probabilities: \t[0.4  0.26 0.14] [0.47 0.27 0.16] [0.37 0.3  0.27] [0.7  0.17 0.07] [0.5  0.14 0.11] \n",
      "\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 1.0214\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 42ms/steploss: 1.01\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 23 22]       [8 5 3]       [8 5 4]       [8 4 3]       [ 8  3 14]       \n",
      "probabilities: \t[0.29 0.24 0.23] [0.47 0.27 0.15] [0.42 0.37 0.14] [0.81 0.08 0.06] [0.61 0.11 0.08] \n",
      "\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 1.0182\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 44ms/steploss: 1.00\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[21 23 22]       [8 5 3]       [5 8 4]       [8 4 3]       [8 3 4]       \n",
      "probabilities: \t[0.26 0.25 0.25] [0.46 0.3  0.17] [0.38 0.38 0.19] [0.8  0.08 0.07] [0.59 0.16 0.08] \n",
      "\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 1.0079\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 41ms/steploss: 1.01\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 21 23]       [8 5 3]       [8 5 4]       [8 4 3]       [8 3 4]       \n",
      "probabilities: \t[0.34 0.23 0.21] [0.54 0.25 0.14] [0.46 0.3  0.16] [0.83 0.08 0.04] [0.62 0.13 0.08] \n",
      "\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 1.0066\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 35ms/steploss: 0.98\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[23 26 21]       [8 5 3]       [8 4 5]       [8 4 3]       [8 9 4]       \n",
      "probabilities: \t[0.29 0.25 0.24] [0.58 0.17 0.16] [0.39 0.31 0.24] [0.75 0.17 0.04] [0.4  0.15 0.14] \n",
      "\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.9876\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 43ms/steploss: 0.98\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[23 26 21]       [8 5 3]       [8 5 4]       [8 4 3]       [8 3 4]       \n",
      "probabilities: \t[0.33 0.28 0.18] [0.49 0.28 0.16] [0.43 0.3  0.23] [0.84 0.06 0.05] [0.62 0.15 0.1 ] \n",
      "\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.9763\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 44ms/steploss: 0.95\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 23 21]       [8 5 3]       [8 4 5]       [8 4 3]       [8 4 3]       \n",
      "probabilities: \t[0.36 0.23 0.19] [0.44 0.3  0.17] [0.36 0.35 0.22] [0.78 0.14 0.04] [0.45 0.17 0.12] \n",
      "\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.9633\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 53ms/steploss: 0.96\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 21 22]       [8 3 5]       [8 5 4]       [8 3 4]       [8 3 9]       \n",
      "probabilities: \t[0.28 0.28 0.21] [0.39 0.28 0.22] [0.33 0.31 0.29] [0.79 0.08 0.08] [0.43 0.24 0.14] \n",
      "\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.9605\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 53ms/steploss: 0.94\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 22 21]       [8 5 3]       [8 5 4]       [8 4 3]       [ 8 14  3]       \n",
      "probabilities: \t[0.31 0.25 0.21] [0.48 0.27 0.19] [0.44 0.26 0.25] [0.87 0.06 0.03] [0.51 0.13 0.11] \n",
      "\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.9572\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 45ms/steploss: 0.93\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 21 22]       [8 5 3]       [5 8 4]       [8 4 3]       [8 4 3]       \n",
      "probabilities: \t[0.32 0.27 0.23] [0.4  0.29 0.26] [0.41 0.32 0.23] [0.79 0.1  0.05] [0.47 0.17 0.17] \n",
      "\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.9351\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 38ms/steploss: 0.93\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[22 26 21]       [8 5 3]       [5 8 4]       [8 5 4]       [8 3 4]       \n",
      "probabilities: \t[0.42 0.23 0.19] [0.41 0.31 0.2 ] [0.44 0.34 0.14] [0.83 0.06 0.05] [0.53 0.17 0.15] \n",
      "\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.9328\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 49ms/steploss: 0.94\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 21 23]       [8 5 3]       [5 4 8]       [8 4 5]       [8 4 3]       \n",
      "probabilities: \t[0.42 0.23 0.22] [0.4  0.31 0.2 ] [0.34 0.31 0.31] [0.77 0.12 0.05] [0.48 0.21 0.18] \n",
      "\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.9353\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 34ms/steploss: 0.90\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 21 22]       [8 5 3]       [8 5 4]       [8 4 3]       [8 4 3]       \n",
      "probabilities: \t[0.29 0.29 0.18] [0.45 0.3  0.21] [0.37 0.33 0.26] [0.84 0.08 0.03] [0.44 0.19 0.17] \n",
      "\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.9099\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 50ms/steploss: 0.90\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[22 26 21]       [8 5 3]       [8 5 4]       [8 5 3]       [8 3 4]       \n",
      "probabilities: \t[0.29 0.28 0.2 ] [0.54 0.27 0.15] [0.47 0.34 0.13] [0.9  0.04 0.03] [0.65 0.16 0.07] \n",
      "\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.9065\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 39ms/steploss: 0.91\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 21 22]       [8 3 5]       [5 8 4]       [8 4 5]       [8 3 9]       \n",
      "probabilities: \t[0.3  0.26 0.25] [0.49 0.23 0.21] [0.41 0.34 0.17] [0.9  0.03 0.03] [0.61 0.14 0.09] \n",
      "\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.9108\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 40ms/steploss: 0.89\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 23 21]       [8 3 5]       [4 8 5]       [8 4 3]       [8 3 4]       \n",
      "probabilities: \t[0.46 0.22 0.22] [0.51 0.2  0.2 ] [0.42 0.27 0.26] [0.87 0.07 0.03] [0.53 0.15 0.14] \n",
      "\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.8987\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 60ms/steploss: 0.88\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 21 22]       [8 5 3]       [8 4 5]       [8 4 3]       [8 3 4]       \n",
      "probabilities: \t[0.39 0.3  0.12] [0.44 0.33 0.17] [0.34 0.31 0.3 ] [0.86 0.07 0.03] [0.56 0.18 0.13] \n",
      "\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.8907\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 56ms/steploss: 0.86\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[21 26 22]       [8 3 5]       [8 5 4]       [8 3 5]       [8 3 4]       \n",
      "probabilities: \t[0.33 0.28 0.18] [0.46 0.24 0.22] [0.41 0.36 0.17] [0.91 0.03 0.03] [0.64 0.17 0.07] \n",
      "\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 0.8698\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 56ms/steploss: 0.86\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[21 26 23]       [8 5 3]       [8 4 5]       [8 4 3]       [ 8  9 14]       \n",
      "probabilities: \t[0.33 0.24 0.22] [0.61 0.17 0.15] [0.48 0.26 0.2 ] [0.92 0.04 0.02] [0.51 0.13 0.13] \n",
      "\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.8632\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 48ms/steploss: 0.84\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[21 26 22]       [8 5 3]       [5 8 4]       [8 5 4]       [8 3 9]       \n",
      "probabilities: \t[0.32 0.29 0.23] [0.39 0.23 0.23] [0.4  0.35 0.19] [0.91 0.04 0.03] [0.64 0.12 0.08] \n",
      "\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.8540\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 46ms/steploss: 0.83\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 21 22]       [8 3 5]       [8 4 5]       [8 4 3]       [8 9 3]       \n",
      "probabilities: \t[0.36 0.25 0.18] [0.37 0.34 0.15] [0.35 0.35 0.23] [0.9  0.04 0.03] [0.53 0.13 0.12] \n",
      "\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 0.8399\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 39ms/steploss: 0.82\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 22 21]       [3 8 5]       [8 5 4]       [8 4 5]       [8 3 9]       \n",
      "probabilities: \t[0.42 0.24 0.21] [0.37 0.35 0.2 ] [0.39 0.37 0.18] [0.92 0.03 0.03] [0.61 0.13 0.09] \n",
      "\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 0.8257\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 59ms/steploss: 0.82\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 21 22]       [3 8 5]       [4 8 5]       [8 4 5]       [8 9 4]       \n",
      "probabilities: \t[0.38 0.27 0.11] [0.4  0.33 0.16] [0.49 0.23 0.22] [0.88 0.07 0.02] [0.45 0.15 0.14] \n",
      "\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.8234\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 44ms/steploss: 0.80\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[21 26 23]       [3 8 5]       [4 8 5]       [8 4 3]       [ 8  9 14]       \n",
      "probabilities: \t[0.3  0.28 0.21] [0.37 0.3  0.1 ] [0.56 0.24 0.12] [0.92 0.04 0.02] [0.47 0.28 0.09] \n",
      "\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.8040\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 44ms/steploss: 0.82\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 23 21]       [8 3 5]       [4 5 8]       [8 4 5]       [8 3 4]       \n",
      "probabilities: \t[0.29 0.28 0.17] [0.37 0.36 0.2 ] [0.35 0.33 0.27] [0.9  0.04 0.03] [0.73 0.11 0.08] \n",
      "\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.8190\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 34ms/steploss: 0.81\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[22 26 21]       [3 8 5]       [4 5 8]       [8 4 5]       [8 3 9]       \n",
      "probabilities: \t[0.27 0.23 0.19] [0.41 0.29 0.17] [0.52 0.27 0.15] [0.87 0.05 0.04] [0.65 0.13 0.07] \n",
      "\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.8130\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 51ms/steploss: 0.78\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 23 21]       [3 8 5]       [4 5 8]       [8 4 5]       [8 4 3]       \n",
      "probabilities: \t[0.29 0.26 0.19] [0.51 0.22 0.12] [0.52 0.22 0.19] [0.88 0.07 0.03] [0.64 0.11 0.11] \n",
      "\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.7859\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 43ms/steploss: 0.77\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[23 21 26]       [3 8 5]       [8 5 4]       [8 5 4]       [8 3 9]       \n",
      "probabilities: \t[0.32 0.24 0.24] [0.42 0.31 0.14] [0.37 0.33 0.23] [0.93 0.04 0.02] [0.78 0.11 0.05] \n",
      "\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.7805\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 39ms/steploss: 0.77\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 21 23]       [3 8 5]       [4 5 8]       [8 4 5]       [8 9 3]       \n",
      "probabilities: \t[0.29 0.23 0.22] [0.38 0.31 0.13] [0.54 0.22 0.18] [0.87 0.07 0.03] [0.55 0.21 0.09] \n",
      "\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.7742\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 40ms/steploss: 0.76\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[21 26 23]       [3 8 5]       [5 8 4]       [8 5 4]       [8 3 9]       \n",
      "probabilities: \t[0.27 0.27 0.26] [0.39 0.26 0.14] [0.35 0.3  0.28] [0.93 0.03 0.02] [0.69 0.13 0.07] \n",
      "\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 0.7628\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 40ms/steploss: 0.74\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[23 21 26]       [3 8 5]       [4 8 5]       [8 4 5]       [8 3 9]       \n",
      "probabilities: \t[0.31 0.2  0.2 ] [0.46 0.28 0.11] [0.43 0.27 0.24] [0.94 0.03 0.02] [0.62 0.15 0.12] \n",
      "\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 0.7430\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 49ms/steploss: 0.74\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[23 26 21]       [3 5 8]       [4 5 8]       [8 5 4]       [8 3 4]       \n",
      "probabilities: \t[0.26 0.21 0.18] [0.63 0.16 0.14] [0.5  0.36 0.1 ] [0.84 0.1  0.05] [0.52 0.21 0.11] \n",
      "\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 0.7429\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 51ms/steploss: 0.74\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 23 21]       [3 8 5]       [4 5 8]       [8 5 4]       [8 3 4]       \n",
      "probabilities: \t[0.31 0.25 0.18] [0.64 0.18 0.11] [0.52 0.23 0.18] [0.93 0.04 0.02] [0.72 0.13 0.06] \n",
      "\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.7472\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 51ms/steploss: 0.73\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[21 23 26]       [ 3  8 21]       [4 5 8]       [8 5 4]       [8 3 9]       \n",
      "probabilities: \t[0.37 0.23 0.22] [0.45 0.23 0.13] [0.39 0.27 0.26] [0.94 0.03 0.02] [0.62 0.17 0.13] \n",
      "\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.7404\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 51ms/steploss: 0.71\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 21 23]       [3 8 5]       [4 5 8]       [8 5 4]       [8 3 9]       \n",
      "probabilities: \t[0.34 0.27 0.21] [0.55 0.2  0.13] [0.54 0.28 0.14] [0.9  0.07 0.02] [0.66 0.2  0.05] \n",
      "\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.7273\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 37ms/steploss: 0.70\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 23 21]       [3 8 5]       [4 5 8]       [8 5 4]       [8 3 9]       \n",
      "probabilities: \t[0.45 0.16 0.16] [0.56 0.18 0.17] [0.52 0.27 0.16] [0.92 0.04 0.04] [0.67 0.17 0.07] \n",
      "\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.7165\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 17ms/steploss: 0.69\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[21 26 25]       [ 3  8 21]       [4 5 8]       [8 5 4]       [8 3 9]       \n",
      "probabilities: \t[0.34 0.26 0.16] [0.41 0.26 0.1 ] [0.34 0.3  0.26] [0.93 0.03 0.02] [0.73 0.11 0.06] \n",
      "\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.7085\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 17ms/steploss: 0.70\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[21 22 26]       [3 8 5]       [4 5 8]       [8 5 4]       [8 9 3]       \n",
      "probabilities: \t[0.29 0.2  0.2 ] [0.57 0.11 0.08] [0.73 0.16 0.08] [0.91 0.06 0.02] [0.67 0.13 0.12] \n",
      "\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.7022\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 18ms/steploss: 0.69\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[26 21 23]       [3 8 5]       [4 5 8]       [8 5 4]       [8 3 9]       \n",
      "probabilities: \t[0.32 0.26 0.14] [0.48 0.13 0.12] [0.54 0.26 0.11] [0.91 0.07 0.01] [0.65 0.18 0.12] \n",
      "\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.6890\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 18ms/steploss: 0.66\n",
      "\n",
      "masked nb: \t 1                2                3                4                5                \n",
      "predictions: \t[23 21 25]       [3 8 5]       [4 5 8]       [8 5 4]       [8 3 4]       \n",
      "probabilities: \t[0.31 0.26 0.17] [0.6  0.2  0.09] [0.76 0.11 0.1 ] [0.95 0.02 0.02] [0.78 0.12 0.04] \n",
      "\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.6777\n"
     ]
    }
   ],
   "source": [
    "# A callback in Keras is a function that is called at certain points during the training process. -> Here is called after each epoch during the training\n",
    "# Here we use to see the \"performance\" at each epoch while predicting on a \"test set\" aka the sample_tokens\n",
    "bert_masked_model.fit(mlm_ds, epochs=100, callbacks=[generator_callback]) \n",
    "bert_masked_model.save(\"bert_models/bert_mlm.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "Predictions:\n",
      " [[26 21 26 21 21 26 21 25 21 23 21 21 26 21 21 26 21 23  3  8  3  3  3  3\n",
      "   3  3  3  3  4  8  4  4  8  3 16 20 21 26 21 23  3  3  8  3  8  3  8  8\n",
      "   8  8  8  8  3  8 10  9 10  9  9 15 14 11  9  9 13 11 14 14 13 14 10 11\n",
      "   9  9 13 14 13 14 11  9 10 14 13 11 11  9 14  9 14 15 20 15 15 17 20 20\n",
      "  20  7  7  9  9  9 20 20 20 20 20  8  8  8  8 23 23 13 13 13 15  3 11 11\n",
      "  10  8  8 15  3  3 14  9]]\n",
      "Original:\n",
      " [[26  2 26 21 21 26 23 25 21 23  2 21 26 21 21 26 21 25  3  8  3  3  3  3\n",
      "   3  3  3  3  7  8  4  2  8  3 16 20 21 26 21 23 21  3  8  7  8  3  5  8\n",
      "   4  8  2  8  3  8 10  9 10  9  9 15 20 11  9 14 13 11  9 14 13 14 10 11\n",
      "   9  9 13 14 13 14 11  9 10 14 13 10 11  9 14  9 14 15 20 15 15 17 20  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0]]\n",
      "Masked:\n",
      " [[26  2 26 21 21 26  9 25 21 23  2 21 26 21 21 26 21  1  3  8  3  1  3  3\n",
      "   3  3  3  3  7  8  1  2  8  3 16 20 21 26 21 23 21  3  8  7  8  3  5  8\n",
      "   4  1  2  8  3  1 10  9 10  9  9 15  1 11  9  1  1 11  9 14 13 14 10  1\n",
      "   9  9 13 14 13 14 11  9 10 14 13 10 11  1 14  9  1 15 20 15 15 17 20  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "predictions = bert_masked_model.predict(x_masked_encoded[0:1])\n",
    "\n",
    "predictions_max = np.argmax(predictions, axis=2)\n",
    "print(\"Predictions:\\n\",predictions_max)\n",
    "print(\"Original:\\n\", y_masked_encoded[0:1])\n",
    "print(\"Masked:\\n\", x_masked_encoded[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True False  True  True  True  True False  True  True  True False  True\n",
      "   True  True  True  True  True False  True  True  True  True  True  True\n",
      "   True  True  True  True False  True  True False  True  True  True  True\n",
      "   True  True  True  True False  True  True False  True  True False  True\n",
      "  False  True False  True  True  True  True  True  True  True  True  True\n",
      "  False  True  True False  True  True False  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True False\n",
      "   True  True  True  True  True  True  True  True  True  True  True False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False]]\n",
      "Accuracy brut:  0.8\n",
      "Accuracy without taking in acount padding:  0.8421052631578947\n",
      "Accuracy on masked tokens:  0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "print(predictions_max == y_masked_encoded[0:1])\n",
    "# print accuracy\n",
    "print(\"Accuracy brut: \", np.sum(predictions_max == y_masked_encoded[0:1]) / (100*len(y_masked_encoded[0:1])))\n",
    "# print accuracy without padding\n",
    "print(\"Accuracy without taking in acount padding: \", np.sum((predictions_max == y_masked_encoded[0:1]) * (y_masked_encoded[0:1] != 0)) / np.sum(y_masked_encoded[0:1] != 0))\n",
    "print(\"Accuracy on masked tokens: \", np.sum((predictions_max == y_masked_encoded[0:1]) * (x_masked_encoded[0:1] == config.TOKEN_DICT['[MASK]'])) / np.sum(x_masked_encoded[0:1] == config.TOKEN_DICT['[MASK]']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def get_end_to_end(model):\\n    inputs = keras.Input(shape=(None,))\\n    outputs = model(inputs)\\n    reshaped_outputs = keras.layers.Lambda(lambda x: keras.backend.argmax(x, axis=-1))(outputs)\\n    end_to_end_model = keras.Model(inputs, reshaped_outputs, name=\"end_to_end_model\")\\n    optimizer = keras.optimizers.Adam(learning_rate=config.bert.LR)\\n    end_to_end_model.compile(\\n        optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\\n    )\\n    return end_to_end_model\\n\\nend_to_end_classification_model = get_end_to_end(bert_masked_model)\\n\\n# Build dataset for end to end model input (will be used at the end)\\ntest_raw_classifier_ds = tf.data.Dataset.from_tensor_slices((x_masked_encoded, y_masked_encoded)).batch(config.BATCH_SIZE)\\n\\nend_to_end_classification_model.evaluate(test_raw_classifier_ds)'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This how we can load a Keras model\n",
    "\"\"\"# Load OUR pretrained bert model\n",
    "mlm_model = keras.models.load_model(\n",
    "    \"bert_mlm_imdb.keras\", custom_objects={\"MaskedLanguageModel\": MaskedLanguageModel}\n",
    ")\"\"\"\n",
    "\n",
    "# Kinda failed attempt to create a end to end model (we don't really need it) -> But it's a good example of how to create a model with a custom loss function and reshape the output\n",
    "\"\"\"def get_end_to_end(model):\n",
    "    inputs = keras.Input(shape=(None,))\n",
    "    outputs = model(inputs)\n",
    "    reshaped_outputs = keras.layers.Lambda(lambda x: keras.backend.argmax(x, axis=-1))(outputs)\n",
    "    end_to_end_model = keras.Model(inputs, reshaped_outputs, name=\"end_to_end_model\")\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=config.bert.LR)\n",
    "    end_to_end_model.compile(\n",
    "        optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return end_to_end_model\n",
    "\n",
    "end_to_end_classification_model = get_end_to_end(bert_masked_model)\n",
    "\n",
    "# Build dataset for end to end model input (will be used at the end)\n",
    "test_raw_classifier_ds = tf.data.Dataset.from_tensor_slices((x_masked_encoded, y_masked_encoded)).batch(config.BATCH_SIZE)\n",
    "\n",
    "end_to_end_classification_model.evaluate(test_raw_classifier_ds)\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
